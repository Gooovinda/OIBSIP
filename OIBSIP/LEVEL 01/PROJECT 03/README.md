### 🧹 Project 03: Data Cleaning

#### 📌 Objective:

In this project, I focused on cleaning and preprocessing real-world datasets to ensure high-quality data for analysis. Messy and inconsistent data can lead to unreliable insights, so this project emphasizes the importance of data cleaning as a core skill in data analytics.

#### 📂 Datasets Used:

1. **Housing Dataset** (P3 D1)
   *(Used for practicing missing value treatment and duplicate removal)*
2. **YouTube Trending Videos Dataset** (P3 D2)
   *(Multiple regional CSVs combined into one large dataset)*

#### 🛠️ Tools & Libraries:

* **Python**
* **Pandas**
* **NumPy**
* **Matplotlib**
* **Seaborn**

#### 🔍 Steps Performed:

* Combined multiple CSV files into a single dataframe (for the YouTube dataset)
* Checked for missing values and nulls
* Dropped or filled missing data where necessary (e.g., 'description' column in YouTube data)
* Removed duplicate entries
* Verified data types and corrected them
* Saved the cleaned datasets for further use

#### ✅ Outcome:

* Successfully cleaned both datasets with **0 missing values** and **0 duplicate rows** remaining.
* Improved dataset quality to ensure they’re ready for analysis and modeling.
* Gained strong hands-on practice with essential data cleaning techniques.

#### 📌 Notes:

* Due to file size limitations, the raw datasets are not uploaded to GitHub.
* 
  ✅ \[Dataset download links are provided here:
  1) Housing Dataset - P3D1
      [https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data].
  3) YouTube Trending Videos Dataset - P3D2
     
[https://www.kaggle.com/datasets/datasnaek/youtube-new].
